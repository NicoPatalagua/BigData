{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark-Dataframes-Windows¶.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN71Ew4Ic4rvtBoDLysxlq8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoPatalagua/BigData/blob/master/Spark_Dataframes_Windows.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47CCUKp7RAsS",
        "colab_type": "text"
      },
      "source": [
        "# **Taller Spark-Dataframes-Windows**\n",
        "## *Paula Oviedo - Nicolás Patalagua*\n",
        "## Infraestructura para BigData\n",
        "\n",
        "# **Spark**\n",
        "[Apache Spark](https://spark.apache.org/) es un framework de computación en clúster open-source. Spark fue desarrollado en sus inicios por Matei Zaharia en la Universidad de California,el AMPLab de la UC Berkeley en 2009. Fue liberado como código abierto en 2010 bajo licencia BSD. El código base del proyecto Spark fue donado más tarde a la Apache Software Foundation que se encarga de su mantenimiento desde entonces. \n",
        "\n",
        "## **¿Para que sirve Spark?**\n",
        "\n",
        "*Spark proporciona una interfaz para la programación de clusters completos con Paralelismo de Datos implícito y tolerancia a fallos.Apache Spark se puede considerar un sistema de computación en clúster de propósito general y orientado a la velocidad. Proporciona APIs en Java, Scala, Python y R. También proporciona un motor optimizado que soporta la ejecución de grafos en general. También soporta un conjunto extenso y rico de herramientas de alto nivel entre las que se incluyen Spark SQL (para el procesamiento de datos estructurados basada en SQL), MLlib para implementar machine learning, GraphX para el procesamiento de grafos y Spark Streaming.*\n",
        "\n",
        "# **Funciones de ventana en Spark**\n",
        "*Las funciones de ventana permiten a los usuarios de Spark SQL calcular resultados como el rango de una fila determinada o un promedio móvil en un rango de filas de entrada. Mejoran significativamente la expresividad de las API de SQL y DataFrame de Spark.\n",
        "En esencia, una función de ventana calcula un valor de retorno para cada fila de entrada de una tabla en función de un grupo de filas, llamado Marco . Cada fila de entrada puede tener un marco único asociado. Esta característica de las funciones de ventana las hace más potentes que otras funciones y permite a los usuarios expresar varias tareas de procesamiento de datos que son difíciles (si no imposibles) de expresar de manera concisa sin las funciones de ventana.* \n",
        "\n",
        "http://queirozf.com/entries/spark-dataframe-examples-window-functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGn1vKcUQywj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "b2a82417-2d95-41ee-9eca-f2ba530f0a83"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "import os\n",
        "import time \n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from pyspark import SparkConf, SparkContext\n",
        "conf = SparkConf().setAppName(\"app\")\n",
        "sc = SparkContext.getOrCreate();"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 54kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 44.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=d8274614e957c8b4058b5efe5a7c3597c869494bc5f62f137956c380d51ce65e\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmnKrbToRRL1",
        "colab_type": "text"
      },
      "source": [
        "# ***Taller***\n",
        "**1. Descargar las acciones de Ecopetrol, Avianca, y Grupo Aval para el último año de Yahoo finances(23 de sept-2018 y 23 de sept-2019).** \n",
        "\n",
        "*Los CSV de acciones se obtienen de [Yahho! Finance](https://finance.yahoo.com/), el cual es un servicio de Yahoo! que proporciona información financiera y comentarios con un enfoque en los mercados de los Estados Unidos.*\n",
        "\n",
        "\n",
        "\n",
        "Las acciones de [Ecopetrol](www.ecopetrol.com.co) se pueden consultar en [EC-Yahoo! Finance](https://finance.yahoo.com/quote/EC?p=EC&.tsrc=fin-srch), y pertenecen a la primera compañía de petróleo de Colombia, antiguamente llamada Empresa Colombiana de Petróleos S.A.Es la cuarta empresa petrolera más grande de Latinoamérica.\n",
        "\n",
        "Las acciones de [Avianca S.A](www.avianca.com) se pueden consultar en [AVH-Yahoo! Finance](https://finance.yahoo.com/quote/AVH?p=AVH&.tsrc=fin-srch), y pertenecen a Aerovías del Continente Americano, anteriormente Aerovías Nacionales de Colombia. Es la mayor aerolínea de Colombia. Fundada en 1919 con el nombre de SCADTA, es mundialmente la segunda aerolínea más antigua después de la KLM que fue fundada 58 días antes y la más antigua del mundo con operaciones ininterrumpidas.\n",
        "\n",
        "Las acciones del [Grupo Aval](www.grupoaval.com) se pueden consultar en [AVA-Yahoo! Finance](https://finance.yahoo.com/quote/AVAL?p=AVAL&.tsrc=fin-srch), corresponden a las acciones del Grupo Acciones y Valores S.A, un n conglomerado empresarial colombiano dedicado a una amplia variedad de actividades, principalmente financieras. El Grupo AVAL es controlado por Luis Carlos Sarmiento Angulo.\n",
        "\n",
        "Una vez descargados son agregados a un repositorio de Github:\n",
        "\n",
        "\n",
        "*   [EC](https://github.com/NicoPatalagua/BigData/blob/master/EC.csv)\n",
        "*   [AVH](https://github.com/NicoPatalagua/BigData/blob/master/AVH.csv)\n",
        "*   [AVA](https://github.com/NicoPatalagua/BigData/blob/master/AVA.csv)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDMUQbCBS_2E",
        "colab_type": "text"
      },
      "source": [
        "**2.Porcentaje de retorno diaro.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGNSTeAATLM4",
        "colab_type": "text"
      },
      "source": [
        "**3.Porcentaje de retorno Mensual.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxT2ZPqlTNPB",
        "colab_type": "text"
      },
      "source": [
        "**4.Mes con mayor porcentaje de retorno.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lS7MixwTNHd",
        "colab_type": "text"
      },
      "source": [
        "**5.Hallar y gráficar la media móvil de 20 dias para Ecopetrol.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goEAvAshTNBJ",
        "colab_type": "text"
      },
      "source": [
        "**6.Graficar comportamiento del precio de cierre para las 3 acciones a lo largo del año.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vcv20qT8TM65",
        "colab_type": "text"
      },
      "source": [
        "**7.Calcular y graficar franajas Bollinger para K=2.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBo35jQ4TM0-",
        "colab_type": "text"
      },
      "source": [
        "**8.Para qué fechas la tendecia se sale de las franjas calculadas en el punto anterior?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0exKlZqxTLje",
        "colab_type": "text"
      },
      "source": [
        "**9.Calcular y graficar las franjas Bollinger con K=2 y K=1.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCgl-CdjTL_W",
        "colab_type": "text"
      },
      "source": [
        "**10.Determinar para qué fechas es conveniente comprar usando la técnica de doble franja Bollinger.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n12C_guHTpOC",
        "colab_type": "text"
      },
      "source": [
        "**11.Determinar para qué fechas es conveniente vender en corto la técnica de doble franja Bollinger.**"
      ]
    }
  ]
}